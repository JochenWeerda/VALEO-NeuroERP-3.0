# L3 â†’ VALEO-NeuroERP OCR-Migration Pipeline

Automatisierte Extraktion und Migration aller L3-Masken zu strukturierten Tabellendefinitionen fÃ¼r den VALEO-NeuroERP Mask Builder.

## ğŸ¯ Ziel

**Input:** L3-Screenshots (Guacamole RDP)  
**Output:** Mask Builder JSON-Schemas + SQL CREATE TABLE Statements

## ğŸ—ï¸ Architektur

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ L3-Screenshot   â”‚
â”‚ (Guacamole RDP) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OCR-Pipeline    â”‚ â† pytesseract + OpenCV
â”‚ (Feldextraktion)â”‚    image_to_data (Bounding Boxes)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM-Analyse     â”‚ â† Claude/GPT
â”‚ (Strukturierung)â”‚    Typ-Erkennung, Validierung
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Schema-Generatorâ”‚ â† Mask Builder Format
â”‚ + L3-Mapping    â”‚    + SQL CREATE TABLE
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ JSON + SQL      â”‚
â”‚ Export          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### 1. Python-Dependencies

```bash
pip install pytesseract pillow opencv-python
```

### 2. Tesseract-OCR Binary

**Windows:**
```powershell
# Als Administrator:
choco install tesseract

# Oder manuell von:
# https://github.com/UB-Mannheim/tesseract/wiki
```

**Linux:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-deu
```

### 3. Verifikation

```bash
python -c "import pytesseract; print('âœ… pytesseract OK')"
tesseract --version
```

## ğŸš€ Quick Start

### Option A: Vollautomatisch (Batch-Modus)

```bash
cd l3-migration-toolkit
python auto-capture-all-masks.py
```

**Workflow:**
1. Script zeigt Maske an (z.B. "Artikelstamm")
2. Sie Ã¶ffnen Maske in L3 (Browser)
3. Sie drÃ¼cken Enter
4. Screenshot wird erstellt
5. OCR-Analyse lÃ¤uft automatisch
6. JSON + SQL wird exportiert
7. Weiter zur nÃ¤chsten Maske

**Output:**
- `schemas/mask-builder/*.json` - Mask Builder Schemas
- `schemas/sql/*.sql` - SQL CREATE TABLE Statements
- `screenshots/l3-masks/*.png` - Screenshots

### Option B: Einzelne Maske (manuell)

```bash
# 1. Screenshot erstellen (manuell)
# 2. OCR-Analyse
python ocr-pipeline.py screenshots/l3-masks/artikelstamm.png --debug

# 3. LLM-Analyse
python llm-field-analyzer.py artikelstamm.ocr.json --mask-name "Artikelstamm"

# 4. Schema-Generator
python analyze-mask-fields.py
```

## ğŸ“‹ Zu erfassende Masken (15+)

### â­â­â­â­â­ KRITISCH
- [x] Artikelstamm
- [ ] Kundenstamm
- [ ] Lieferschein
- [ ] Rechnung
- [ ] Auftrag
- [ ] Bestellung
- [ ] Lager-Bestand
- [ ] PSM-Abgabe (Agrar!)

### â­â­â­â­ WICHTIG
- [ ] Lieferantenstamm
- [ ] Angebot
- [ ] Wareneingang
- [ ] Kunden-Kontoauszug

### â­â­â­ NICE-TO-HAVE
- [ ] Inventur
- [ ] Saatgut
- [ ] DÃ¼nger

## ğŸ”§ Module

### 1. `ocr-pipeline.py`

**Funktion:** Screenshot â†’ OCR â†’ Strukturierte Felder

```python
from ocr_pipeline import L3MaskOCR

ocr = L3MaskOCR()
results = ocr.extract_fields("artikelstamm.png")

print(results['fields'])  # Liste erkannter Felder
print(results['tabs'])    # Liste erkannter Tabs
```

**Features:**
- Preprocessing (Graustufen, Kontrast, Rauschreduzierung)
- Bounding Boxes fÃ¼r prÃ¤zise Feldposition
- Feldtyp-Erkennung (Lookup, Dropdown, Checkbox, etc.)
- Tab-Extraktion

### 2. `llm-field-analyzer.py`

**Funktion:** OCR-Rohdaten â†’ LLM â†’ Strukturierte Felddefinition

```python
from llm_field_analyzer import LLMFieldAnalyzer

analyzer = LLMFieldAnalyzer()
analyzed = analyzer.analyze_ocr_with_llm(
    ocr_text=results['raw_text'],
    ocr_fields=results['fields'],
    context={'mask_name': 'Artikelstamm'}
)
```

**Features:**
- Intelligente Typzuordnung (Text, Nummer, Datum, Currency, etc.)
- Validierungs-Erkennung (required, unique, max_length)
- L3 â†’ VALEO Mapping-Integration
- Relations-Erkennung (Foreign Keys)

### 3. `analyze-mask-fields.py`

**Funktion:** Structured Fields â†’ Mask Builder JSON + SQL

```python
from analyze_mask_fields import L3MaskAnalyzer

analyzer = L3MaskAnalyzer()
schema = analyzer.generate_from_ocr("artikelstamm.png", "Artikelstamm")

analyzer.export_to_json(schema, "schemas/mask-builder/artikelstamm.json")
analyzer.export_to_sql(schema, "schemas/sql/artikelstamm.sql")
```

**Output-Format:**
```json
{
  "schema_version": "1.0",
  "mask": {
    "id": "artikelstamm",
    "name": "Artikel-Stammdaten",
    "route": "/artikel/stamm"
  },
  "form": {
    "fields": [...],
    "validation": {...},
    "layout": {"type": "tabs"}
  },
  "database": {
    "table": "artikelstamm",
    "columns": [...],
    "relations": [...]
  }
}
```

### 4. `auto-capture-all-masks.py`

**Funktion:** Orchestrierung - 15+ Masken automatisch erfassen

```bash
python auto-capture-all-masks.py
```

## ğŸ“Š Erfolgsmetriken

- âœ… **100%** der L3-Masken gescreenshottet
- âœ… **95%+** OCR-Genauigkeit (manuelles Review)
- âœ… **Alle Schemas** importierbar in Mask Builder
- âœ… **SQL-Statements** direkt ausfÃ¼hrbar in PostgreSQL

## ğŸ”— Integration mit existierendem L3-Mapping

Die Pipeline nutzt automatisch das existierende Mapping:

**Datei:** `scripts/l3_import_mapping.json`

```json
{
  "ARTIKEL": {
    "ARTIKEL_NR": {
      "source_column": "ARTIKEL_NR",
      "target_column": "artikel_nr",
      "type": "VARCHAR(20)"
    },
    ...
  }
}
```

**Verwendung:**
- Automatische Zuordnung von L3-Feldnamen zu VALEO-Spaltennamen
- Typkonvertierung
- Relations-Ableitung

## ğŸ› Troubleshooting

### Problem: Tesseract nicht gefunden

```
FileNotFoundError: [WinError 2] The system cannot find the file specified
```

**LÃ¶sung:**
```python
# In ocr-pipeline.py:
ocr = L3MaskOCR(tesseract_path="C:/Program Files/Tesseract-OCR/tesseract.exe")
```

### Problem: Niedrige OCR-Genauigkeit

**LÃ¶sung:**
1. Screenshot-QualitÃ¤t erhÃ¶hen (hÃ¶here AuflÃ¶sung)
2. Debug-Modus aktivieren: `--debug`
3. Preprocessing-Parameter anpassen (in `ocr-pipeline.py`)

### Problem: LLM-Integration fehlt

**LÃ¶sung:**
```python
# In llm-field-analyzer.py, _call_llm():
import openai

response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": prompt}]
)
```

## ğŸ“š WeiterfÃ¼hrende Dokumentation

- [L3-Tabellenstruktur](../scripts/l3_tables_postgres.sql)
- [L3-Import-Mapping](../scripts/l3_import_mapping.json)
- [VALEO-NeuroERP Mask Builder](../docs/MASK-BUILDER-GUIDE.md)

## ğŸ¤ Workflow-Beispiel

```bash
# Terminal 1: Browser Ã¶ffnen
http://localhost:8090/guacamole/#/client/MQBjAHBvc3RncmVzcWw

# Terminal 2: Pipeline starten
cd l3-migration-toolkit
python auto-capture-all-masks.py

# Schritt 1: Artikelstamm
# - In L3: ERFASSUNG â†’ Artikel-Stamm Ã¶ffnen
# - Enter drÃ¼cken
# - Screenshot wird erstellt
# - OCR + LLM analysiert (30s)
# - JSON + SQL exportiert

# Schritt 2: Kundenstamm
# - In L3: ERFASSUNG â†’ Kunden Ã¶ffnen
# - Enter drÃ¼cken
# ...

# Nach 15+ Masken:
# âœ… schemas/mask-builder/ enthÃ¤lt alle JSONs
# âœ… schemas/sql/ enthÃ¤lt alle SQL-Statements
```

## ğŸ“ˆ Status

**Aktuell implementiert:**
- [x] OCR-Pipeline mit Preprocessing
- [x] LLM-Feldanalyse (Struktur)
- [x] Schema-Generator (JSON + SQL)
- [x] L3-Mapping-Integration
- [x] Batch-Automation-Script
- [ ] LLM-API-Integration (OpenAI/Anthropic)
- [ ] Playwright-MCP Screenshot-Automation
- [ ] Mask Builder Import-Funktion

**NÃ¤chste Schritte:**
1. Tesseract installieren (einmalig)
2. Erste 5 Masken manuell erfassen
3. OCR-Parameter optimieren
4. LLM-API einbinden
5. Vollautomatische Erfassung aller 15+ Masken

---

**Bereit fÃ¼r die Migration! ğŸš€**

